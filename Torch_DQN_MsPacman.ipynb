{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4259548d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\torch_env\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\User\\anaconda3\\envs\\torch_env\\lib\\site-packages\\torch\\utils\\tensorboard\\__init__.py:4: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not hasattr(tensorboard, \"__version__\") or LooseVersion(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import gym\n",
    "import numpy as np\n",
    "import cv2\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import statistics\n",
    "\n",
    "# Preprocess each frame from 210x160 to 84x84\n",
    "class Preprocess(gym.ObservationWrapper):\n",
    "    \n",
    "    def __init__(self, env=None):\n",
    "        super(Preprocess, self).__init__(env)\n",
    "        self.observation_space = gym.spaces.Box(low=0, high=255, shape=(84, 84, 1), dtype=np.uint8)\n",
    "\n",
    "    def observation(self, obs):\n",
    "        return Preprocess.process(obs)\n",
    "\n",
    "    def process(frame):\n",
    "        frame = np.reshape(frame, [210, 160, 1]).astype(np.uint8)\n",
    "        resized_frame = cv2.resize(frame, (84, 110), interpolation=cv2.INTER_AREA)\n",
    "        result = resized_frame[18:102, :]\n",
    "        result = np.reshape(result, [84, 84, 1])\n",
    "        return result.astype(np.uint8)\n",
    "\n",
    "# Change axis accordingly to neural network input\n",
    "class ChangeAxis(gym.ObservationWrapper):\n",
    "    \n",
    "    def __init__(self, env):\n",
    "        super(ChangeAxis, self).__init__(env)\n",
    "        old_shape = self.observation_space.shape\n",
    "        self.observation_space = gym.spaces.Box(low=0, high=255, shape=(old_shape[-1], old_shape[0], old_shape[1]), dtype=np.uint8)\n",
    "\n",
    "    def observation(self, observation):\n",
    "        return np.moveaxis(observation, 2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2eab2c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convolutional neural network\n",
    "class DQN_Network(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_shape, n_actions):\n",
    "        super(DQN_Network, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(input_shape[0], 32, kernel_size=8, stride=4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        output_size = self.get_output_size(input_shape)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(output_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, n_actions)\n",
    "        )\n",
    "    \n",
    "    def get_output_size(self, input_shape):\n",
    "        ot = self.conv(torch.zeros(1, *input_shape))\n",
    "        return int(np.prod(ot.size()))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.float() / 255.0\n",
    "        mid_output = self.conv(x).view(x.size()[0], -1)\n",
    "        return self.fc(mid_output)\n",
    "\n",
    "#DQN agent \n",
    "class DQN_Agent:\n",
    "\n",
    "    def __init__(self, state_space, action_space, epsilon_max, epsilon_min, rb_size, batch_size, gamma, lr):\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.state_space = state_space\n",
    "        self.action_space = action_space        \n",
    "       \n",
    "        self.dqn = DQN_Network(state_space, action_space).to(self.device)\n",
    "        self.dqn_target = DQN_Network(state_space, action_space).to(self.device)\n",
    "        \n",
    "        self.optimizer = torch.optim.Adam(self.dqn.parameters(), lr=lr)\n",
    "        self.l1 = nn.SmoothL1Loss().to(self.device)\n",
    "        self.batch_size = batch_size\n",
    "        self.gamma = gamma\n",
    "        \n",
    "        self.epsilon = epsilon_max\n",
    "        self.epsilon_max = epsilon_max\n",
    "        self.epsilon_min = epsilon_min\n",
    "        self.epsilon_decay = (epsilon_max - epsilon_min)/20000\n",
    "\n",
    "        self.mem_size = rb_size\n",
    "        self.state_buffer = torch.zeros(self.mem_size, *self.state_space, dtype=torch.uint8)\n",
    "        self.action_buffer = torch.zeros(self.mem_size, 1)\n",
    "        self.reward_buffer = torch.zeros(self.mem_size, 1)\n",
    "        self.next_state_buffer = torch.zeros(self.mem_size, *self.state_space, dtype=torch.uint8)\n",
    "        self.done_buffer = torch.zeros(self.mem_size, 1)\n",
    "        self.last_pos = 0\n",
    "        self.current = 0\n",
    "    \n",
    "    def select_action(self, state):\n",
    "        if random.random() < self.epsilon:  \n",
    "            return torch.tensor([[random.randrange(self.action_space)]])\n",
    "        else:\n",
    "            return torch.argmax(self.dqn(state.to(self.device))).unsqueeze(0).unsqueeze(0).cpu()\n",
    "    \n",
    "    def train(self):\n",
    "        if self.batch_size > self.current:\n",
    "            return\n",
    "        \n",
    "        states, actions, rewards, next_states, dones = self.sample()\n",
    "        states = states.float().to(self.device)\n",
    "        actions = actions.float().to(self.device)\n",
    "        rewards = rewards.float().to(self.device)\n",
    "        next_states = next_states.float().to(self.device)\n",
    "        dones = dones.float().to(self.device)\n",
    "        \n",
    "        self.optimizer.zero_grad()\n",
    "        current = self.dqn(states).gather(1, actions.long())\n",
    "        target = rewards + torch.mul((self.gamma * self.dqn_target(next_states).max(1).values.unsqueeze(1)), 1 - dones)\n",
    "    \n",
    "        loss = self.l1(current, target)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        self.epsilon -= self.epsilon_decay\n",
    "        self.epsilon = max(self.epsilon, self.epsilon_min)\n",
    "        \n",
    "    def store(self, state, action, reward, next_state, done):\n",
    "        self.state_buffer[self.last_pos] = state\n",
    "        self.action_buffer[self.last_pos] = action\n",
    "        self.reward_buffer[self.last_pos] = reward\n",
    "        self.next_state_buffer[self.last_pos] = next_state\n",
    "        self.done_buffer[self.last_pos] = done\n",
    "        \n",
    "        self.last_pos = (self.last_pos + 1) % self.mem_size\n",
    "        self.current = min(self.current + 1, self.mem_size)\n",
    "    \n",
    "    def sample(self):\n",
    "        indices = random.choices(range(self.current), k=self.batch_size)\n",
    "        states = self.state_buffer[indices]\n",
    "        actions = self.action_buffer[indices]\n",
    "        rewards = self.reward_buffer[indices]\n",
    "        next_states = self.next_state_buffer[indices]\n",
    "        dones = self.done_buffer[indices]      \n",
    "        return states, actions, rewards, next_states, dones\n",
    "        \n",
    "    def update_target(self):\n",
    "         self.dqn_target.load_state_dict(self.dqn.state_dict())\n",
    "            \n",
    "    def save_models(self):\n",
    "        torch.save(self.dqn.state_dict(), \"state_dict_model.pt\")\n",
    "        torch.save(self.dqn_target.state_dict(), \"state_dict_target_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fe10d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train run\n",
    "def train_agent(episodes=2000):\n",
    "    \n",
    "    writer = SummaryWriter()\n",
    "   \n",
    "    env = gym.make('ALE/MsPacman-v5', frameskip=16, obs_type='grayscale')\n",
    "    env.seed(12)\n",
    "    env.action_space.seed(12)\n",
    "    env = Preprocess(env)\n",
    "    env = ChangeAxis(env) \n",
    "     \n",
    "    state_space = env.observation_space.shape\n",
    "    action_space = env.action_space.n\n",
    "    agent = DQN_Agent(state_space=state_space, action_space=action_space, epsilon_max=1.0, epsilon_min=0.02, rb_size=200000, batch_size=32, gamma=0.95, lr=0.00025)\n",
    "    \n",
    "    update_target = 200\n",
    "    total_steps = 0\n",
    "          \n",
    "    for episode in range(episodes):\n",
    "        episode_score = 0\n",
    "        step = 0\n",
    "        \n",
    "        state = env.reset()\n",
    "        state = torch.from_numpy(np.array(state)).unsqueeze(0)\n",
    "        \n",
    "        while True:\n",
    "            action = agent.select_action(state)\n",
    "            step += 1\n",
    "            \n",
    "            next_state, reward, done, info = env.step(int(action[0]))\n",
    "            next_state = torch.from_numpy(np.array(next_state)).unsqueeze(0)\n",
    "            episode_score += reward  \n",
    "                    \n",
    "            agent.store(state, action, reward, next_state, done)\n",
    "            agent.train()\n",
    "            if step % update_target == 0:\n",
    "                agent.update_target()\n",
    "            \n",
    "            state = next_state\n",
    "            \n",
    "            if done:\n",
    "                total_steps += step\n",
    "                writer.add_scalar(\"Score/Step\", episode_score, total_steps)\n",
    "                writer.add_scalar(\"Score/Episode\", episode_score, episode)\n",
    "                writer.flush()\n",
    "                break        \n",
    "        \n",
    "    agent.save_models()\n",
    "    env.close()\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcc0a416",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\torch_env\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:97: UserWarning: \u001b[33mWARN: We recommend you to use a symmetric and normalized Box action space (range=[-1, 1]) https://stable-baselines3.readthedocs.io/en/master/guide/rl_tips.html\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 101 score = 1580.0, average score = 593.6633663366337, total steps = 14886\n",
      "Episode 201 score = 400.0, average score = 713.2835820895523, total steps = 30918\n",
      "Episode 301 score = 1410.0, average score = 781.5614617940199, total steps = 47986\n",
      "Episode 401 score = 700.0, average score = 907.4812967581047, total steps = 66324\n",
      "Episode 501 score = 720.0, average score = 993.7325349301398, total steps = 84939\n",
      "Episode 601 score = 1040.0, average score = 1053.5607321131447, total steps = 103501\n",
      "Episode 701 score = 2140.0, average score = 1104.7646219686162, total steps = 122487\n",
      "Episode 801 score = 1850.0, average score = 1147.6404494382023, total steps = 142504\n",
      "Episode 901 score = 1810.0, average score = 1203.6625971143174, total steps = 162951\n",
      "Episode 1001 score = 1040.0, average score = 1257.4925074925075, total steps = 183498\n",
      "Episode 1101 score = 1110.0, average score = 1296.4850136239781, total steps = 204242\n",
      "Episode 1201 score = 1210.0, average score = 1340.7160699417152, total steps = 225403\n",
      "Episode 1301 score = 1820.0, average score = 1376.7563412759416, total steps = 245973\n",
      "Episode 1401 score = 1960.0, average score = 1408.9507494646682, total steps = 266779\n",
      "Episode 1501 score = 2610.0, average score = 1427.4017321785477, total steps = 286760\n",
      "Episode 1601 score = 1980.0, average score = 1456.2773266708307, total steps = 307390\n",
      "Episode 1701 score = 3030.0, average score = 1488.3597883597884, total steps = 328727\n",
      "Episode 1801 score = 2650.0, average score = 1519.9000555247085, total steps = 349900\n",
      "Episode 1901 score = 1560.0, average score = 1540.3051025775908, total steps = 370675\n",
      "Episode 2001 score = 2330.0, average score = 1561.5792103948027, total steps = 392102\n",
      "Episode 2101 score = 2580.0, average score = 1577.415516420752, total steps = 412809\n",
      "Episode 2201 score = 2130.0, average score = 1595.0068150840527, total steps = 433188\n",
      "Episode 2301 score = 910.0, average score = 1617.8357235984354, total steps = 454771\n",
      "Episode 2401 score = 2130.0, average score = 1651.6992919616825, total steps = 475804\n",
      "Episode 2501 score = 2660.0, average score = 1677.4010395841663, total steps = 496702\n",
      "Episode 2601 score = 1890.0, average score = 1699.1157247212611, total steps = 518121\n",
      "Episode 2701 score = 2440.0, average score = 1719.2225101814142, total steps = 539412\n",
      "Episode 2801 score = 3270.0, average score = 1728.7183148875401, total steps = 560242\n",
      "Episode 2901 score = 1980.0, average score = 1741.9407100999656, total steps = 581455\n",
      "Episode 3001 score = 810.0, average score = 1748.9236921026325, total steps = 602269\n",
      "Episode 3101 score = 1230.0, average score = 1757.5556272170268, total steps = 623522\n",
      "Episode 3201 score = 1950.0, average score = 1767.3445798188066, total steps = 644290\n",
      "Episode 3301 score = 1040.0, average score = 1772.6234474401697, total steps = 664627\n",
      "Episode 3401 score = 2000.0, average score = 1784.7250808585711, total steps = 685022\n",
      "Episode 3501 score = 2670.0, average score = 1795.3041988003426, total steps = 706249\n",
      "Episode 3601 score = 2020.0, average score = 1808.669813940572, total steps = 727150\n",
      "Episode 3701 score = 790.0, average score = 1818.4328559848689, total steps = 748300\n",
      "Episode 3801 score = 1640.0, average score = 1825.1249671139174, total steps = 768883\n",
      "Episode 3901 score = 2480.0, average score = 1826.4239938477313, total steps = 789226\n",
      "Episode 4001 score = 2310.0, average score = 1833.094226443389, total steps = 809278\n",
      "Episode 4101 score = 1100.0, average score = 1842.7017800536455, total steps = 830420\n",
      "Episode 4201 score = 3180.0, average score = 1849.4715543918114, total steps = 850961\n",
      "Episode 4301 score = 2870.0, average score = 1856.556614740758, total steps = 871131\n",
      "Episode 4401 score = 1950.0, average score = 1869.3410588502613, total steps = 891751\n",
      "Episode 4501 score = 2440.0, average score = 1876.6874027993779, total steps = 912591\n",
      "Episode 4601 score = 2000.0, average score = 1884.679417517931, total steps = 933272\n",
      "Episode 4701 score = 2430.0, average score = 1894.1012550521166, total steps = 954078\n",
      "Episode 4801 score = 1720.0, average score = 1906.1862112059987, total steps = 975461\n",
      "Episode 4901 score = 1430.0, average score = 1915.7294429708222, total steps = 996361\n",
      "Episode 5001 score = 1310.0, average score = 1926.502699460108, total steps = 1017205\n",
      "Episode 5101 score = 1210.0, average score = 1934.8363066065476, total steps = 1037672\n",
      "Episode 5201 score = 3250.0, average score = 1946.1988079215535, total steps = 1058587\n",
      "Episode 5301 score = 2310.0, average score = 1953.3672891907188, total steps = 1079773\n",
      "Episode 5401 score = 2810.0, average score = 1961.4552860581373, total steps = 1101229\n",
      "Episode 5501 score = 2280.0, average score = 1967.962188692965, total steps = 1122148\n",
      "Episode 5601 score = 2080.0, average score = 1974.5509730405286, total steps = 1143051\n",
      "Episode 5701 score = 1430.0, average score = 1987.3653744957026, total steps = 1165010\n",
      "Episode 5801 score = 2510.0, average score = 1998.884675056025, total steps = 1186013\n",
      "Episode 5901 score = 2080.0, average score = 2001.9674631418404, total steps = 1207407\n",
      "Episode 6001 score = 2630.0, average score = 2001.3731044825863, total steps = 1228065\n",
      "Episode 6101 score = 3310.0, average score = 2007.4791017865923, total steps = 1249007\n",
      "Episode 6201 score = 3250.0, average score = 2017.866473149492, total steps = 1270494\n",
      "Episode 6301 score = 4060.0, average score = 2030.2079035073798, total steps = 1292135\n",
      "Episode 6401 score = 1960.0, average score = 2045.62255897516, total steps = 1313825\n",
      "Episode 6501 score = 3280.0, average score = 2060.8552530379943, total steps = 1335414\n",
      "Episode 6601 score = 740.0, average score = 2076.3566126344494, total steps = 1356955\n",
      "Episode 6701 score = 2310.0, average score = 2088.5226085658855, total steps = 1378512\n",
      "Episode 6801 score = 1590.0, average score = 2098.016468166446, total steps = 1399757\n",
      "Episode 6901 score = 5480.0, average score = 2108.5494855817997, total steps = 1421673\n",
      "Episode 7001 score = 4270.0, average score = 2125.02928153121, total steps = 1443303\n",
      "Episode 7101 score = 1820.0, average score = 2144.0388677651035, total steps = 1464482\n",
      "Episode 7201 score = 1750.0, average score = 2162.944035550618, total steps = 1486340\n",
      "Episode 7301 score = 2610.0, average score = 2174.393918641282, total steps = 1507178\n",
      "Episode 7401 score = 4260.0, average score = 2187.455749223078, total steps = 1529104\n",
      "Episode 7501 score = 2670.0, average score = 2202.7463004932674, total steps = 1551033\n",
      "Episode 7601 score = 1870.0, average score = 2217.199052756216, total steps = 1573236\n",
      "Episode 7701 score = 1220.0, average score = 2234.1020646669263, total steps = 1596040\n",
      "Episode 7801 score = 1830.0, average score = 2248.0271760030764, total steps = 1617664\n",
      "Episode 7901 score = 4420.0, average score = 2270.9429186178963, total steps = 1640674\n",
      "Episode 8001 score = 4270.0, average score = 2285.3468316460444, total steps = 1662810\n",
      "Episode 8101 score = 4310.0, average score = 2306.964572275028, total steps = 1685297\n",
      "Episode 8201 score = 3330.0, average score = 2319.6780880380443, total steps = 1706730\n",
      "Episode 8301 score = 2890.0, average score = 2329.7000361402243, total steps = 1727571\n",
      "Episode 8401 score = 3650.0, average score = 2344.7946673015117, total steps = 1749040\n",
      "Episode 8501 score = 4600.0, average score = 2359.9141277496765, total steps = 1770955\n",
      "Episode 8601 score = 2070.0, average score = 2380.025578421114, total steps = 1792892\n",
      "Episode 8701 score = 5420.0, average score = 2397.586484312148, total steps = 1813958\n",
      "Episode 8801 score = 1940.0, average score = 2416.7412794000684, total steps = 1836260\n",
      "Episode 8901 score = 5630.0, average score = 2426.7374452308727, total steps = 1857875\n",
      "Episode 9001 score = 3400.0, average score = 2436.8014665037217, total steps = 1879606\n",
      "Episode 9101 score = 3280.0, average score = 2445.626854191847, total steps = 1901246\n",
      "Episode 9201 score = 960.0, average score = 2451.054233235518, total steps = 1922144\n",
      "Episode 9301 score = 1920.0, average score = 2460.5977851843886, total steps = 1943342\n",
      "Episode 9401 score = 1160.0, average score = 2471.9859589405382, total steps = 1964641\n",
      "Episode 9501 score = 2830.0, average score = 2487.049784233239, total steps = 1986577\n",
      "Episode 9601 score = 2570.0, average score = 2495.9639620872827, total steps = 2008430\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 9701 score = 2320.0, average score = 2509.4516029275333, total steps = 2031312\n",
      "Episode 9801 score = 5860.0, average score = 2522.7619630649933, total steps = 2052852\n",
      "Episode 9901 score = 5720.0, average score = 2538.028481971518, total steps = 2074666\n",
      "Episode 10001 score = 5020.0, average score = 2549.76902309769, total steps = 2097273\n",
      "Episode 10101 score = 4000.0, average score = 2567.123057123057, total steps = 2119070\n",
      "Episode 10201 score = 1540.0, average score = 2579.457896284678, total steps = 2141656\n",
      "Episode 10301 score = 2900.0, average score = 2587.532278419571, total steps = 2162887\n",
      "Episode 10401 score = 4240.0, average score = 2591.826747428132, total steps = 2184191\n",
      "Episode 10501 score = 3700.0, average score = 2597.3564422435957, total steps = 2205620\n",
      "Episode 10601 score = 2750.0, average score = 2608.492595038204, total steps = 2227646\n",
      "Episode 10701 score = 1570.0, average score = 2617.8674890197176, total steps = 2249972\n",
      "Episode 10801 score = 1630.0, average score = 2630.293491343394, total steps = 2272272\n",
      "Episode 10901 score = 4050.0, average score = 2638.3726263645535, total steps = 2293725\n",
      "Episode 11001 score = 1370.0, average score = 2645.610399054631, total steps = 2315956\n",
      "Episode 11101 score = 4930.0, average score = 2650.7629943248357, total steps = 2337806\n",
      "Episode 11201 score = 3210.0, average score = 2661.1106151236495, total steps = 2359938\n",
      "Episode 11301 score = 3590.0, average score = 2666.098575347314, total steps = 2382016\n",
      "Episode 11401 score = 2110.0, average score = 2672.332251556881, total steps = 2404439\n",
      "Episode 11501 score = 4830.0, average score = 2678.127988870533, total steps = 2425997\n",
      "Episode 11601 score = 3230.0, average score = 2690.336177915697, total steps = 2448165\n",
      "Episode 11701 score = 6140.0, average score = 2705.495256815657, total steps = 2470529\n",
      "Episode 11801 score = 1540.0, average score = 2723.016693500551, total steps = 2494076\n",
      "Episode 11901 score = 1700.0, average score = 2737.6548189227797, total steps = 2515882\n",
      "Episode 12001 score = 7490.0, average score = 2755.2587284392966, total steps = 2538755\n",
      "Episode 12101 score = 6220.0, average score = 2773.3947607635732, total steps = 2561729\n",
      "Episode 12201 score = 4410.0, average score = 2780.1081878534546, total steps = 2583769\n",
      "Episode 12301 score = 4010.0, average score = 2796.576701081213, total steps = 2606285\n",
      "Episode 12401 score = 3260.0, average score = 2799.5193935972907, total steps = 2627233\n",
      "Episode 12501 score = 2650.0, average score = 2805.0587952963765, total steps = 2649122\n",
      "Episode 12601 score = 420.0, average score = 2811.8569954765494, total steps = 2670346\n",
      "Episode 12701 score = 1880.0, average score = 2816.876623887883, total steps = 2691804\n",
      "Episode 12801 score = 6050.0, average score = 2826.9767986876027, total steps = 2714158\n",
      "Episode 12901 score = 7790.0, average score = 2841.983567165336, total steps = 2736735\n",
      "Episode 13001 score = 4080.0, average score = 2849.7423275132683, total steps = 2759362\n",
      "Episode 13101 score = 5610.0, average score = 2857.938325318678, total steps = 2781707\n",
      "Episode 13201 score = 4350.0, average score = 2871.73017195667, total steps = 2804429\n",
      "Episode 13301 score = 1130.0, average score = 2888.5083828283587, total steps = 2827262\n",
      "Episode 13401 score = 2550.0, average score = 2900.7454667562124, total steps = 2849679\n",
      "Episode 13501 score = 4450.0, average score = 2911.29323753796, total steps = 2872816\n",
      "Episode 13601 score = 3130.0, average score = 2917.190647746489, total steps = 2894726\n",
      "Episode 13701 score = 1710.0, average score = 2920.924020144515, total steps = 2916301\n",
      "Episode 13801 score = 5180.0, average score = 2927.5704659082676, total steps = 2938535\n",
      "Episode 13901 score = 1730.0, average score = 2935.9823034314077, total steps = 2960980\n",
      "Episode 14001 score = 6020.0, average score = 2945.45818155846, total steps = 2983124\n",
      "Episode 14101 score = 2800.0, average score = 2957.4023118927735, total steps = 3006062\n",
      "Episode 14201 score = 3130.0, average score = 2964.2750510527426, total steps = 3027604\n",
      "Episode 14301 score = 2910.0, average score = 2970.224459827984, total steps = 3050430\n",
      "Episode 14401 score = 750.0, average score = 2975.1267273106037, total steps = 3073030\n",
      "Episode 14501 score = 4330.0, average score = 2985.7637404316943, total steps = 3095845\n",
      "Episode 14601 score = 2240.0, average score = 2994.414081227313, total steps = 3117752\n",
      "Episode 14701 score = 3530.0, average score = 2998.296034283382, total steps = 3139837\n",
      "Episode 14801 score = 2570.0, average score = 3003.0011485710424, total steps = 3161916\n",
      "Episode 14901 score = 2710.0, average score = 3009.3060868398093, total steps = 3184018\n",
      "Episode 15001 score = 5760.0, average score = 3013.2957802813144, total steps = 3205636\n",
      "Episode 15101 score = 7580.0, average score = 3025.304946692272, total steps = 3228116\n",
      "Episode 15201 score = 3370.0, average score = 3036.5725939082954, total steps = 3250815\n",
      "Episode 15301 score = 4900.0, average score = 3041.1783543559245, total steps = 3272378\n",
      "Episode 15401 score = 8220.0, average score = 3048.3929614960066, total steps = 3294516\n",
      "Episode 15501 score = 1430.0, average score = 3059.353590090962, total steps = 3317941\n",
      "Episode 15601 score = 4860.0, average score = 3067.608486635472, total steps = 3340740\n",
      "Episode 15701 score = 2520.0, average score = 3071.8533851347047, total steps = 3362478\n",
      "Episode 15801 score = 1150.0, average score = 3078.1653059932914, total steps = 3384621\n",
      "Episode 15901 score = 4950.0, average score = 3080.018866737941, total steps = 3406359\n",
      "Episode 16001 score = 1570.0, average score = 3085.306543341041, total steps = 3428798\n",
      "Episode 16101 score = 1820.0, average score = 3091.731569467735, total steps = 3451237\n",
      "Episode 16201 score = 4720.0, average score = 3101.6579223504723, total steps = 3473904\n",
      "Episode 16301 score = 4640.0, average score = 3111.9311698668794, total steps = 3497162\n",
      "Episode 16401 score = 4950.0, average score = 3120.3658313517467, total steps = 3519361\n",
      "Episode 16501 score = 4960.0, average score = 3125.1124174292468, total steps = 3541495\n",
      "Episode 16601 score = 3180.0, average score = 3126.941148123607, total steps = 3562194\n",
      "Episode 16701 score = 2530.0, average score = 3128.8389916771453, total steps = 3584193\n",
      "Episode 16801 score = 5700.0, average score = 3131.579667876912, total steps = 3606495\n",
      "Episode 16901 score = 1570.0, average score = 3134.321046091947, total steps = 3628708\n",
      "Episode 17001 score = 3220.0, average score = 3136.337274277984, total steps = 3650467\n",
      "Episode 17101 score = 4140.0, average score = 3139.229869598269, total steps = 3672099\n",
      "Episode 17201 score = 1530.0, average score = 3143.5922330097087, total steps = 3694600\n",
      "Episode 17301 score = 7730.0, average score = 3150.4415929715046, total steps = 3717048\n",
      "Episode 17401 score = 2360.0, average score = 3158.39549451181, total steps = 3739662\n",
      "Episode 17501 score = 4500.0, average score = 3163.336380778241, total steps = 3761640\n",
      "Episode 17601 score = 5850.0, average score = 3171.684563377081, total steps = 3784453\n",
      "Episode 17701 score = 5840.0, average score = 3176.4408790463817, total steps = 3807118\n",
      "Episode 17801 score = 4410.0, average score = 3186.485028930959, total steps = 3830294\n",
      "Episode 17901 score = 2760.0, average score = 3190.4502541757442, total steps = 3851865\n",
      "Episode 18001 score = 1290.0, average score = 3200.1277706794067, total steps = 3874874\n",
      "Episode 18101 score = 5110.0, average score = 3203.727970830341, total steps = 3896876\n",
      "Episode 18201 score = 1070.0, average score = 3206.798527553431, total steps = 3918915\n",
      "Episode 18301 score = 2310.0, average score = 3210.2365990929457, total steps = 3941493\n",
      "Episode 18401 score = 1740.0, average score = 3216.0811912396066, total steps = 3963546\n",
      "Episode 18501 score = 2230.0, average score = 3223.938706015891, total steps = 3985966\n",
      "Episode 18601 score = 2900.0, average score = 3228.5269609160796, total steps = 4008122\n",
      "Episode 18701 score = 4610.0, average score = 3228.859419282391, total steps = 4029776\n",
      "Episode 18801 score = 1700.0, average score = 3234.8343173235467, total steps = 4052412\n",
      "Episode 18901 score = 5550.0, average score = 3240.293106184858, total steps = 4074792\n",
      "Episode 19001 score = 4010.0, average score = 3245.49813167728, total steps = 4097756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 19101 score = 4330.0, average score = 3247.592272655882, total steps = 4120295\n",
      "Episode 19201 score = 4390.0, average score = 3251.5921045778864, total steps = 4142873\n",
      "Episode 19301 score = 4420.0, average score = 3254.0324335526657, total steps = 4165496\n",
      "Episode 19401 score = 1690.0, average score = 3255.929075820834, total steps = 4187821\n",
      "Episode 19501 score = 4290.0, average score = 3258.533408543152, total steps = 4209698\n",
      "Episode 19601 score = 4350.0, average score = 3265.321157083822, total steps = 4232881\n",
      "Episode 19701 score = 1240.0, average score = 3268.7432110045174, total steps = 4255070\n",
      "Episode 19801 score = 4140.0, average score = 3274.7436998131407, total steps = 4277744\n",
      "Episode 19901 score = 4790.0, average score = 3282.43756595146, total steps = 4301891\n",
      "Episode 20000 score = 5160.0, average score = 3289.3625, total steps = 4324932\n"
     ]
    }
   ],
   "source": [
    "train_agent(episodes=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34c584b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agent evaluation after training\n",
    "def evaluate():\n",
    "    env = gym.make('ALE/MsPacman-v5', frameskip=16, obs_type='grayscale', render_mode= 'human')\n",
    "    env = Preprocess(env)\n",
    "    env = ChangeAxis(env) \n",
    "\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    model = DQN_Network(env.observation_space.shape, env.action_space.n).to(device)\n",
    "    model.load_state_dict(torch.load(\"state_dict_model.pt\"))\n",
    "    model.eval()\n",
    "\n",
    "    epsilon = 0.02\n",
    "\n",
    "    scores = []\n",
    "\n",
    "    for i in range(30):\n",
    "        episode_score = 0\n",
    "        state = env.reset()\n",
    "        state = torch.from_numpy(np.array(state)).unsqueeze(0)\n",
    "    \n",
    "        while True:\n",
    "            if random.random() < epsilon:  \n",
    "                action =  torch.tensor([[random.randrange(9)]])\n",
    "            else:\n",
    "                action = torch.argmax(model(state.to(device))).unsqueeze(0).unsqueeze(0).cpu()\n",
    "            \n",
    "            next_state, reward, done, info = env.step(int(action[0]))\n",
    "            next_state = torch.from_numpy(np.array(next_state)).unsqueeze(0)\n",
    "            episode_score += reward  \n",
    "        \n",
    "            state = next_state\n",
    "        \n",
    "            if done:\n",
    "                scores.append(episode_score)\n",
    "                print(\"Episode: {}, Score: {}\" .format(i + 1, scores[-1]))\n",
    "                break\n",
    "            \n",
    "    print(\"Avarage score: {}\" .format(np.mean(scores)))\n",
    "    print(statistics.stdev(scores))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d197a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\torch_env\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:97: UserWarning: \u001b[33mWARN: We recommend you to use a symmetric and normalized Box action space (range=[-1, 1]) https://stable-baselines3.readthedocs.io/en/master/guide/rl_tips.html\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch_env]",
   "language": "python",
   "name": "conda-env-torch_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
